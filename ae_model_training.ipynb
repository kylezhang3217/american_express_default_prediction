{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#custom helper service\n",
    "from data_training_service_classification import data_training_service_classification\n",
    "from data_ml_models_service import data_ml_models_service\n",
    "\n",
    "from data_persistence import save_object, load_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the attributes\n",
    "attr = load_object('american_express_training_attributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_3_last</th>\n",
       "      <th>D_44_mean</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>R_1_mean</th>\n",
       "      <th>B_9_mean</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_44_last</th>\n",
       "      <th>R_1_max</th>\n",
       "      <th>B_2_last</th>\n",
       "      <th>...</th>\n",
       "      <th>B_23_last</th>\n",
       "      <th>R_2_last</th>\n",
       "      <th>P_3_last</th>\n",
       "      <th>S_25_std</th>\n",
       "      <th>B_19_last</th>\n",
       "      <th>R_6_max</th>\n",
       "      <th>R_7_std</th>\n",
       "      <th>B_20_mean</th>\n",
       "      <th>B_37_mean</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.868580</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.934745</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>1.007647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040367</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.629392</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.012015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.929122</td>\n",
       "      <td>0.861109</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>1.004028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.570898</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.025244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.013902</td>\n",
       "      <td>0.904482</td>\n",
       "      <td>0.797670</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.009443</td>\n",
       "      <td>0.812650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020228</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.628938</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009937</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.623392</td>\n",
       "      <td>0.567442</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.052241</td>\n",
       "      <td>0.621776</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>1.006183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.672080</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>0.058964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.940382</td>\n",
       "      <td>0.805045</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.006685</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.815746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145214</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.570419</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458908</th>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.895553</td>\n",
       "      <td>0.730505</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.138467</td>\n",
       "      <td>0.844229</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>1.009867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025304</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.531050</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.027284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458909</th>\n",
       "      <td>0.233078</td>\n",
       "      <td>0.129993</td>\n",
       "      <td>0.868121</td>\n",
       "      <td>0.831279</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>0.186676</td>\n",
       "      <td>0.831279</td>\n",
       "      <td>0.132158</td>\n",
       "      <td>0.008855</td>\n",
       "      <td>0.055656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262849</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.562481</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.750326</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>1.004064</td>\n",
       "      <td>0.368336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458910</th>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>0.802953</td>\n",
       "      <td>0.756983</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.080004</td>\n",
       "      <td>0.800522</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>1.007023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037423</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.616007</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.009790</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.042393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458911</th>\n",
       "      <td>0.050048</td>\n",
       "      <td>0.052808</td>\n",
       "      <td>0.856981</td>\n",
       "      <td>0.754129</td>\n",
       "      <td>0.023470</td>\n",
       "      <td>0.012824</td>\n",
       "      <td>0.754129</td>\n",
       "      <td>0.133062</td>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.714486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263867</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>0.486135</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.009212</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.054238</td>\n",
       "      <td>0.019739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458912</th>\n",
       "      <td>0.014092</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>1.005768</td>\n",
       "      <td>0.965709</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.024574</td>\n",
       "      <td>0.982175</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>0.992880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.611945</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.009942</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.145645</td>\n",
       "      <td>0.038620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410470 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        B_3_last  D_44_mean   P_2_max   P_2_min  R_1_mean  B_9_mean  P_2_last  \\\n",
       "0       0.007174   0.004673  0.960384  0.868580  0.004509  0.006220  0.934745   \n",
       "1       0.005068   0.004311  0.929122  0.861109  0.006246  0.010298  0.880519   \n",
       "2       0.007196   0.013902  0.904482  0.797670  0.006621  0.004730  0.880875   \n",
       "3       0.009937   0.005246  0.623392  0.567442  0.005665  0.052241  0.621776   \n",
       "4       0.005528   0.003551  0.940382  0.805045  0.004180  0.006685  0.871900   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "458908  0.005893   0.005449  0.895553  0.730505  0.005458  0.138467  0.844229   \n",
       "458909  0.233078   0.129993  0.868121  0.831279  0.005542  0.186676  0.831279   \n",
       "458910  0.006314   0.005649  0.802953  0.756983  0.004751  0.080004  0.800522   \n",
       "458911  0.050048   0.052808  0.856981  0.754129  0.023470  0.012824  0.754129   \n",
       "458912  0.014092   0.005066  1.005768  0.965709  0.004153  0.024574  0.982175   \n",
       "\n",
       "        D_44_last   R_1_max  B_2_last  ...  B_23_last  R_2_last  P_3_last  \\\n",
       "0        0.003258  0.009228  1.007647  ...   0.040367  0.008309  0.629392   \n",
       "1        0.008781  0.008996  1.004028  ...   0.014705  0.004976  0.570898   \n",
       "2        0.000628  0.009443  0.812650  ...   0.020228  0.001687  0.628938   \n",
       "3        0.007792  0.009915  1.006183  ...   0.005060  0.004238  0.672080   \n",
       "4        0.002436  0.009076  0.815746  ...   0.145214  0.001991  0.570419   \n",
       "...           ...       ...       ...  ...        ...       ...       ...   \n",
       "458908   0.002280  0.011499  1.009867  ...   0.025304  0.007813  0.531050   \n",
       "458909   0.132158  0.008855  0.055656  ...   0.262849  0.009918  0.562481   \n",
       "458910   0.001022  0.008506  1.007023  ...   0.037423  0.005899  0.616007   \n",
       "458911   0.133062  0.252796  0.714486  ...   0.263867  0.005468  0.486135   \n",
       "458912   0.006794  0.008897  0.992880  ...   0.017935  0.001016  0.611945   \n",
       "\n",
       "        S_25_std  B_19_last   R_6_max   R_7_std  B_20_mean  B_37_mean  target  \n",
       "0       0.002514   0.005274  0.009594  0.002007   0.005731   0.012015       0  \n",
       "1       0.002654   0.008047  0.009253  0.003069   0.004935   0.025244       0  \n",
       "2       0.002843   0.005951  0.009718  0.002910   0.004549   0.004545       0  \n",
       "3       0.002967   0.007715  0.008929  0.003194   0.004058   0.058964       0  \n",
       "4       0.003349   0.006706  0.009199  0.002912   0.004845   0.004030       0  \n",
       "...          ...        ...       ...       ...        ...        ...     ...  \n",
       "458908  0.002029   0.002272  0.009992  0.002657   0.005015   0.027284       0  \n",
       "458909  0.002387   0.750326  0.009524  0.003179   1.004064   0.368336       0  \n",
       "458910  0.002545   0.002565  0.009790  0.002574   0.019333   0.042393       0  \n",
       "458911  0.003612   0.008973  0.009212  0.003553   0.054238   0.019739       1  \n",
       "458912  0.003360   0.008168  0.009942  0.002586   0.145645   0.038620       0  \n",
       "\n",
       "[410470 rows x 52 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = load_object('ae_training_data')\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(training_data.drop('target', axis=1)\n",
    "                                                    , training_data['target']\n",
    "                                                    , test_size=0.2\n",
    "                                                    , random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_svc = data_ml_models_service()\n",
    "logistic_regression_model = dm_svc.get_logistic_regression_model()\n",
    "decision_tree_model = dm_svc.get_decision_tree_classification_model()\n",
    "random_forest_model = dm_svc.get_random_forest_model()\n",
    "gradient_boosted_tree_model = dm_svc.get_gradient_boosted_tree_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = data_training_service_classification(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jw\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(),\n",
       " 'y_test_pred': array([1, 0, 1, ..., 1, 0, 0], dtype=int64),\n",
       " 'y_train_pred': array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " 'test_acc': 88.55,\n",
       " 'train_acc': 88.4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_results = dts.train_model(logistic_regression_model, 5)\n",
    "logistic_regression_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': DecisionTreeClassifier(),\n",
       " 'y_test_pred': array([1, 0, 1, ..., 1, 0, 0], dtype=int64),\n",
       " 'y_train_pred': array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " 'test_acc': 83.83,\n",
       " 'train_acc': 83.91}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_results = dts.train_model(decision_tree_model, 5)\n",
    "decision_tree_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': RandomForestClassifier(),\n",
       " 'y_test_pred': array([1, 0, 1, ..., 1, 0, 0], dtype=int64),\n",
       " 'y_train_pred': array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " 'test_acc': 88.91,\n",
       " 'train_acc': 88.73}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_results = dts.train_model(random_forest_model, 5)\n",
    "random_forest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': GradientBoostingClassifier(),\n",
       " 'y_test_pred': array([1, 0, 1, ..., 1, 0, 0], dtype=int64),\n",
       " 'y_train_pred': array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " 'test_acc': 88.89,\n",
       " 'train_acc': 88.77}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boosted_tree_results = dts.train_model(gradient_boosted_tree_model, 5)\n",
    "gradient_boosted_tree_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persist models\n",
    "save_object(logistic_regression_results['model'], 'logistic_regression_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(decision_tree_results['model'], 'decision_tree_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(random_forest_results['model'], 'random_forest_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(gradient_boosted_tree_results['model'], 'gradient_boosted_tree_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
